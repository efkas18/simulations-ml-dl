{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c490970e-0ddb-40b4-aa93-eb0ea078a25a",
   "metadata": {},
   "source": [
    "# Wine Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6863539a-506e-4030-9ce7-071767fcaafb",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c88bf6c2-642a-4091-867f-4a637767c1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e094ed68-b5bc-4fdb-90e4-0738d4fc44cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba75177c-c684-40be-8640-51989386e53a",
   "metadata": {},
   "source": [
    "## Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "522f5d99-bd4b-4662-ba8d-2b848c7978fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"dataset/winequality-white.csv\", delimiter = ';')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15442611-11a6-4404-a6ef-1fe92d35f918",
   "metadata": {},
   "source": [
    "## Choose implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2e14e5d1-1e35-4720-8470-1e868947275a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represents the separation to binary categories ('good' or 'bad' quality) or evaluation by score degree.\n",
    "# If value is equal to '0', then will be made a score separation above 6.5 or less.\n",
    "# From the other hand a precision score implementation will be adopt.\n",
    "implementation = 0\n",
    "if implementation == 0:\n",
    "    temp_v = []\n",
    "    for i in range(y.shape[0]):\n",
    "        if y[i] > 6.5:\n",
    "            temp_v.append(1)\n",
    "        else:\n",
    "            temp_v.append(0)\n",
    "    y = np.array(temp_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64a74fdd-8a71-4512-b8f1-534b20710355",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 7.    0.27  0.36 ...  3.    0.45  8.8 ]\n",
      " [ 6.3   0.3   0.34 ...  3.3   0.49  9.5 ]\n",
      " [ 8.1   0.28  0.4  ...  3.26  0.44 10.1 ]\n",
      " ...\n",
      " [ 6.5   0.24  0.19 ...  2.99  0.46  9.4 ]\n",
      " [ 5.5   0.29  0.3  ...  3.34  0.38 12.8 ]\n",
      " [ 6.    0.21  0.38 ...  3.26  0.32 11.8 ]]\n"
     ]
    }
   ],
   "source": [
    "print(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "13d00673-e551-4c1f-be71-c6df32ab2019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74799cd1-ab69-44c0-9100-3bad347e5d3f",
   "metadata": {},
   "source": [
    "## Split data to Training and Testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0934168d-eacf-4827-ab95-50e983a398d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "572ec035-0069-4c52-acd4-d45735c6f191",
   "metadata": {},
   "source": [
    "## Feature Scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9722662-fffd-47e6-8892-36343eefb1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X_train = sc.fit_transform(X_train)\n",
    "X_test = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ea5bbd4-4437-4f18-9b5f-b3729f659283",
   "metadata": {},
   "source": [
    "## Define the Machine Learning models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3ea8a47a-8d98-44ea-b7f4-bdae7346dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "## Hyperparameter Tuning function for RandomForectClassifier.\n",
    "def rfc():\n",
    "    from sklearn.model_selection import GridSearchCV\n",
    "    param_grid = {\n",
    "        'n_estimators': [50, 100, 200, 300],\n",
    "        'max_depth': [None, 10, 20, 30, 40],\n",
    "        'min_samples_split': [2, 5, 10, 20]\n",
    "    }\n",
    "    grid_search = GridSearchCV(estimator = RandomForestClassifier(), param_grid = param_grid, cv = 3, n_jobs = -1)\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    best_rf_model = grid_search.best_estimator_\n",
    "    y_pred_rf = best_rf_model.predict(X_test)\n",
    "    \n",
    "    return y_pred_rf\n",
    "\n",
    "# Defines models and passes some basic parameters for each model.\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"K-Neighbours Classifier\": KNeighborsClassifier(n_neighbors = len(np.unique(y)), metric = 'minkowski', p = 2, n_jobs = -1),\n",
    "    \"Support Vector Classifier\": SVC(C = 1, gamma = 0.1),\n",
    "    \"Gaussian Naive Bayes\": GaussianNB(),\n",
    "    \"Decision Tree Classifier\": DecisionTreeClassifier(criterion = 'entropy'),\n",
    "    \"Random Forest Classifier\": rfc()\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e2ddb0-82f2-4f21-94eb-c6cc13e1f82c",
   "metadata": {},
   "source": [
    "## Define metrics to measure the efficieny of each model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "89441e42-c691-46bb-91f1-22434c15952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
    "\n",
    "# Initializes an empty list to store results.\n",
    "results = []\n",
    "for name, model in models.items():\n",
    "    if name != \"Random Forest Classifier\":\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "    else:\n",
    "         y_pred = model\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average = 'weighted')\n",
    "    precision = precision_score(y_test, y_pred, average = 'weighted')\n",
    "    recall = recall_score(y_test, y_pred, average = 'weighted')\n",
    "    \n",
    "    results.append({\n",
    "        \"model\": name,\n",
    "        \"accuracy\": round(accuracy, 4),\n",
    "        \"f1-Score\": round(f1, 4),\n",
    "        \"precision\": round(precision, 4),\n",
    "        \"recall\": round(recall, 4),\n",
    "    })\n",
    "    \n",
    "df_results = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47289085-5cb2-47af-907b-35edbcfae54e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       model  accuracy  f1-Score  precision  recall\n",
      "0        Logistic Regression    0.8000    0.7687     0.7702  0.8000\n",
      "1    K-Neighbours Classifier    0.8433    0.8259     0.8320  0.8433\n",
      "2  Support Vector Classifier    0.8212    0.7950     0.8028  0.8212\n",
      "3       Gaussian Naive Bayes    0.7363    0.7557     0.8008  0.7363\n",
      "4   Decision Tree Classifier    0.8098    0.8136     0.8185  0.8098\n",
      "5   Random Forest Classifier    0.8710    0.8617     0.8646  0.8710\n"
     ]
    }
   ],
   "source": [
    "print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "ab0a9794-48d4-4318-8738-e6e7665782a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model is Random Forest Classifier with accuracy 87.1%\n"
     ]
    }
   ],
   "source": [
    "# Initializes dictionary in order to reveal the best model implementation.\n",
    "best_model = {\n",
    "    'model': '',\n",
    "    'accuracy': 0.0\n",
    "}\n",
    "\n",
    "for index, row in df_results.iterrows():\n",
    "    accuracy = row['accuracy']\n",
    "    model = row['model']\n",
    "    \n",
    "    if best_model['accuracy'] < accuracy:\n",
    "        best_model['model'] = model\n",
    "        best_model['accuracy'] = accuracy\n",
    "        \n",
    "print(f\"Best model is {best_model['model']} with accuracy {round(best_model['accuracy'] * 100, 2)}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
